{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch --no-cache-dir\n",
    "!pip install safetensors albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /content/dataset\n",
    "!cp -r \"/content/drive/MyDrive/cc/Uncropped\" /content/dataset/\n",
    "!cp -r \"/content/drive/MyDrive/cc/Cropped\" /content/dataset/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linknet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import segmentation_models_pytorch as smp\n",
    "from safetensors.torch import load_file\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Load Model Config\n",
    "config_path = \"/content/drive/MyDrive/path_to_model/ln/config.json\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "# Initialize LinkNet Model\n",
    "model = smp.Linknet(\n",
    "    encoder_name=\"tu-resnet18\",  # Using Torchvision ResNet18 (Hugging Face)\n",
    "    encoder_depth=model_config[\"encoder_depth\"],\n",
    "    encoder_weights=model_config[\"encoder_weights\"],  # Pretrained weights\n",
    "    decoder_use_batchnorm=model_config[\"decoder_use_batchnorm\"],\n",
    "    in_channels=model_config[\"in_channels\"],\n",
    "    classes=model_config[\"classes\"],\n",
    "    activation=None\n",
    ").cuda()\n",
    "\n",
    "# Apply TorchDynamo (`torch.compile()`)\n",
    "model = torch.compile(model)  # âš¡ Graph optimization for speedup\n",
    "\n",
    "# Load Pretrained Weights for LinkNet\n",
    "weights_path = \"/content/drive/MyDrive/path_to_model/ln/model.safetensors\"\n",
    "state_dict = load_file(weights_path)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.train()\n",
    "\n",
    "\n",
    "# Dataset Class\n",
    "class ConjunctivaDataset(Dataset):\n",
    "    def __init__(self, image_filenames, mask_filenames, image_dir, mask_dir, transform=None):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.mask_filenames = mask_filenames\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(os.path.join(self.image_dir, self.image_filenames[idx]))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imread(os.path.join(self.mask_dir, self.mask_filenames[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = (mask / 255.0).astype(np.float32)  # Normalize mask\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "\n",
    "        return image, mask.unsqueeze(0)  # Add channel dim\n",
    "\n",
    "# Data Augmentation\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Affine(scale=(0.95, 1.05), translate_percent=(0.05, 0.05), rotate=(-15, 15), p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "], is_check_shapes=False)\n",
    "\n",
    "# Data Loading\n",
    "image_dir = \"/content/dataset/Uncropped\"\n",
    "mask_dir = \"/content/dataset/Cropped\"\n",
    "\n",
    "image_filenames = sorted(os.listdir(image_dir))\n",
    "mask_filenames = sorted(os.listdir(mask_dir))\n",
    "\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(\n",
    "    image_filenames, mask_filenames, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Set num_workers dynamically\n",
    "num_workers = min(4, os.cpu_count() // 2)\n",
    "\n",
    "train_dataset = ConjunctivaDataset(train_images, train_masks, image_dir, mask_dir, transform)\n",
    "val_dataset = ConjunctivaDataset(val_images, val_masks, image_dir, mask_dir, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# Loss Function\n",
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        smooth = 1e-6\n",
    "        intersection = (pred * target).sum()\n",
    "        return 1 - (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "\n",
    "criterion = lambda pred, target: 0.5 * nn.BCEWithLogitsLoss()(pred, target) + 0.5 * DiceLoss()(pred, target)\n",
    "\n",
    "# ðŸ”¹ Optimized Scheduler: ReduceLROnPlateau\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "# Evaluation Metrics\n",
    "def dice_score(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).astype(np.uint8)\n",
    "    target = (target > 0.5).astype(np.uint8)\n",
    "    intersection = np.sum(pred * target)\n",
    "    return (2. * intersection) / (np.sum(pred) + np.sum(target) + 1e-8)\n",
    "\n",
    "def iou_score(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).astype(np.uint8)\n",
    "    target = (target > 0.5).astype(np.uint8)\n",
    "    return jaccard_score(target.flatten(), pred.flatten(), average=\"binary\")\n",
    "\n",
    "def accuracy(pred, target, threshold=0.5):\n",
    "    return np.mean((pred > threshold) == (target > 0.5))\n",
    "\n",
    "# ðŸ”¹ TTA (Test-Time Augmentation)\n",
    "def apply_tta(model, images):\n",
    "    images = images.cuda()\n",
    "    original_preds = torch.sigmoid(model(images)).cpu().numpy()\n",
    "\n",
    "    flipped = torch.flip(images, [3])  # Horizontal Flip\n",
    "    flipped_preds = torch.flip(torch.sigmoid(model(flipped)), [3]).cpu().numpy()\n",
    "\n",
    "    return (original_preds + flipped_preds) / 2  # Average predictions\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "best_dice = 0\n",
    "counter = 0\n",
    "scaler = torch.amp.GradScaler('cuda')  # ðŸ”¹ Use AMP for mixed precision training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.cuda(non_blocking=True), masks.cuda(non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type='cuda'):  # ðŸ”¹ AMP for faster training\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_dice, total_iou, total_acc = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.cuda(non_blocking=True), masks.cuda(non_blocking=True)\n",
    "\n",
    "            outputs = apply_tta(model, images)\n",
    "            masks = masks.cpu().numpy()\n",
    "\n",
    "            total_dice += sum(dice_score(outputs[i], masks[i]) for i in range(len(outputs)))\n",
    "            total_iou += sum(iou_score(outputs[i], masks[i]) for i in range(len(outputs)))\n",
    "            total_acc += sum(accuracy(outputs[i], masks[i]) for i in range(len(outputs)))\n",
    "\n",
    "    num_samples = len(val_dataset)\n",
    "    avg_dice, avg_iou, avg_acc = total_dice / num_samples, total_iou / num_samples, total_acc / num_samples\n",
    "\n",
    "    scheduler.step(avg_dice)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f} | Dice: {avg_dice:.4f} | IoU: {avg_iou:.4f} | Acc: {avg_acc:.4f}\")\n",
    "\n",
    "    if avg_dice > best_dice:\n",
    "        best_dice = avg_dice\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}.\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
